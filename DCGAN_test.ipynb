{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "trunc_normal= tf.truncated_normal_initializer(stddev=0.02)\n",
    "normal = tf.random_normal_initializer(stddev=0.02)\n",
    "\n",
    "from NN_architectures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "BETA1 = 0.5\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "SAVE_SAMPLE_PERIOD = 100\n",
    "\n",
    "#task='TEST'\n",
    "task='TRAIN'\n",
    "\n",
    "PATH='DCGAN_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global d_sizes, g_sizes\n",
    "\n",
    "# # Convolutional layers\n",
    "        \n",
    "d_sizes = {\n",
    "         'conv_layers': [(2, 6, 2, False, 1, lrelu, trunc_normal),\n",
    "                         (64, 6, 2, True, 1, lrelu, trunc_normal)],\n",
    "         'dense_layers': [(1024, True, 1, lrelu ,normal)],\n",
    "}\n",
    "g_sizes = {\n",
    "         'z': 100,\n",
    "         'projection': 128,\n",
    "         'bn_after_project': False,\n",
    "         'dense_layers': [(1024, True, 1, tf.nn.relu, normal)],\n",
    "         'conv_layers': [(128, 6, 2, True, 1, tf.nn.relu ,normal),\n",
    "                         (1, 6, 2, False, 1,  tf.nn.relu, normal)],\n",
    "         'output_activation': tf.sigmoid,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist():\n",
    "    \n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "\n",
    "    X_train = mnist.train.images\n",
    "\n",
    "    X_train = X_train.reshape(len(X_train),28,28,1)\n",
    "    n_H = X_train.shape[1]\n",
    "    n_W = X_train.shape[2]\n",
    "    n_C = X_train.shape[-1]\n",
    "    \n",
    "    X_test = mnist.test.images\n",
    "    X_test = X_test.reshape(len(X_test),28,28,1)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "    gan = DCGAN(n_H, n_W, n_C, d_sizes, g_sizes,\n",
    "                lr=LEARNING_RATE,beta1=BETA1,\n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                save_sample=SAVE_SAMPLE_PERIOD, path=PATH)\n",
    "    \n",
    "    vars_to_train= tf.trainable_variables()\n",
    "    \n",
    "    \n",
    "    if task == 'TRAIN':\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        \n",
    "    if task == 'TEST':\n",
    "        vars_all = tf.global_variables()\n",
    "        vars_to_init = list(set(vars_all)-set(vars_to_train))\n",
    "        init_op = tf.variables_initializer(vars_to_init)\n",
    "        \n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()    \n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "\n",
    "        if task=='TRAIN':\n",
    "            print('\\n Training...')\n",
    "            \n",
    "            if os.path.exists(PATH+'/'+PATH+'.ckpt.index'):\n",
    "                saver.restore(sess,PATH+'/'+PATH+'.ckpt')\n",
    "                print('Model restored.')\n",
    "            \n",
    "            gan.set_session(sess)\n",
    "            gan.fit(X_train)\n",
    "            \n",
    "            save_path = saver.save(sess, PATH+'/'+PATH+'.ckpt')\n",
    "            print(\"Model saved in path: %s\" % save_path)\n",
    "        \n",
    "        if task=='TEST':\n",
    "            print('\\n Evaluate model on test set...')\n",
    "            saver.restore(sess,PATH+'/'+PATH+'.ckpt')\n",
    "            print('Model restored.')\n",
    "            \n",
    "            gan.set_session(sess) \n",
    "            \n",
    "        done = False\n",
    "        while not done:\n",
    "            \n",
    "            \n",
    "            Z_in = np.random.uniform(-1,1, size=(1, g_sizes['z']))\n",
    "            \n",
    "            im = gan.get_sample(Z_in)\n",
    "            \n",
    "            plt.imshow(im.reshape(28,28), cmap='gray')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            ans = input(\"Generate another?\")\n",
    "            if ans and ans[0] in ('n' or 'N'):\n",
    "                done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Convolutional Network architecture detected\n",
      "Convolution\n",
      "Input for convolution shape  (?, 28, 28, 1)\n",
      "(3136, 1024)\n",
      "Logits shape (?, 1)\n",
      "Deconvolution\n",
      "Input for deconvolution shape (?, 100)\n",
      "Deconvoluted output shape (?, 28, 28, 1)\n",
      "Convolution\n",
      "Input for convolution shape  (?, 28, 28, 1)\n",
      "(3136, 1024)\n",
      "Logits shape (?, 1)\n",
      "Deconvolution\n",
      "Input for deconvolution shape (?, 100)\n",
      "Deconvoluted output shape (?, 28, 28, 1)\n",
      "\n",
      " Training...\n",
      "\n",
      " ****** \n",
      "\n",
      "Training DCGAN with a total of 55000 samples distributed in batches of size 128\n",
      "\n",
      "The learning rate set is 0.0001, and every 100 epoch a generated sample will be saved to DCGAN_test\n",
      "\n",
      " ****** \n",
      "\n",
      "Epoch: 0\n",
      "At iter: 100  -  dt: 0:00:00.324827 - d_acc: 0.93\n",
      "Saving a sample...\n",
      "At iter: 200  -  dt: 0:00:00.324019 - d_acc: 0.97\n",
      "Saving a sample...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cluster/dlanci/anaconda3/envs/deepnet/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iter: 300  -  dt: 0:00:00.326484 - d_acc: 0.86\n",
      "Saving a sample...\n",
      "At iter: 400  -  dt: 0:00:00.328076 - d_acc: 0.66\n",
      "Saving a sample...\n",
      "Epoch: 1\n",
      "At iter: 500  -  dt: 0:00:00.327946 - d_acc: 0.69\n",
      "Saving a sample...\n",
      "At iter: 600  -  dt: 0:00:00.336437 - d_acc: 0.69\n",
      "Saving a sample...\n",
      "At iter: 700  -  dt: 0:00:00.329447 - d_acc: 0.68\n",
      "Saving a sample...\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    if task == 'TRAIN':\n",
    "        if not os.path.exists(PATH):\n",
    "            os.mkdir(PATH)\n",
    "    \n",
    "        elif os.path.exists(PATH):\n",
    "            if os.path.exists(PATH+'/checkpoint'):\n",
    "                ans = input('A previous checkpoint exists \\nDo you want to overwrite the current model saved at '+PATH+'/checkpoint?\\n')\n",
    "                if ans and ans[0] in ('n' or 'N'):\n",
    "                    PATH = input('Specify the name of the model, a new directory will be created.\\n')\n",
    "                    os.mkdir(PATH)\n",
    "                else:\n",
    "                    print('Overwriting existing model in '+PATH)\n",
    "                    for file in os.listdir(PATH):\n",
    "                        file_path = os.path.join(PATH, file)\n",
    "                        try:\n",
    "                            if os.path.isfile(file_path):\n",
    "                                os.unlink(file_path)\n",
    "                            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                \n",
    "        mnist()\n",
    "   \n",
    "    elif task == 'TEST': \n",
    "        if not os.path.exists(PATH+'/checkpoint'):\n",
    "            print('No checkpoint to test')\n",
    "        else:\n",
    "            mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
